# LAB6 - Guide de D√©marrage Rapide

## üìã Vue d'Ensemble

Ce projet contient une impl√©mentation compl√®te du LAB6 sur la d√©tection d'objets avec Deep Learning et Transfer Learning.

## üéØ Fichiers Cr√©√©s

### 1. **LAB6_Complete.py** - Code Principal ‚≠ê
Le fichier le plus important qui impl√©mente **TOUS les 4 tasks** du lab :

#### **Task 1: Exploration des Hyperparam√®tres**
- Teste diff√©rents learning rates (0.00001, 0.0001, 0.001)
- Teste diff√©rents batch sizes (1, 2, 4)
- Teste diff√©rents nombres d'√©poques (2, 3, 5)
- G√©n√®re des checkpoints et un fichier JSON de r√©sultats

#### **Task 2: Adaptation Architecturale et Transfer Learning**
- Configuration sans freezing (baseline)
- Configuration avec backbone gel√©
- Configuration avec d√©gel graduel (layer4)
- Configuration avec MobileNetV3
- Compare les performances et temps d'entra√Ænement

#### **Task 3: Transformation et Augmentation de Donn√©es**
- Transform basique (ToTensor seulement)
- Random Horizontal Flip
- Color Jitter
- Normalisation ImageNet
- Augmentation combin√©e
- √âvalue l'impact sur la robustesse

#### **Task 4: √âvaluation et Inf√©rence**
- Teste diff√©rents seuils de confiance (0.3, 0.5, 0.7, 0.9)
- Teste diff√©rents seuils IoU pour NMS (0.3, 0.5, 0.7)
- Compare avec/sans NMS
- G√©n√®re des visualisations

### 2. **quick_demo.py** - D√©mos Rapides üöÄ
Scripts de d√©monstration sans entra√Ænement pour tester rapidement :

- **Demo 1** : D√©tection avec mod√®le pr√©-entra√Æn√©
- **Demo 2** : Comparaison Faster R-CNN vs RetinaNet
- **Demo 3** : Impact du NMS avec diff√©rents seuils
- **Demo 4** : Pipeline d'inf√©rence personnalis√© (classe ObjectDetector)

### 3. **README.md** - Documentation Compl√®te üìñ
Documentation d√©taill√©e avec :
- Description de chaque task
- Format des donn√©es
- Exemples d'utilisation
- Troubleshooting
- R√©sultats attendus

## üöÄ Comment D√©marrer

### √âtape 1: Installer les D√©pendances

```bash
pip install torch torchvision pillow tqdm
```

### √âtape 2: Pr√©parer les Donn√©es

Cr√©er la structure suivante :
```
code/
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ images/      # Vos images .jpg
    ‚îî‚îÄ‚îÄ labels/      # Vos labels .txt (format YOLO)
```

**Format des labels (YOLO)** - Chaque ligne dans le .txt :
```
<class_id> <x_center> <y_center> <width> <height>
```
(Toutes les valeurs normalis√©es entre 0 et 1)

### √âtape 3: Tester Rapidement (Sans Entra√Ænement)

```bash
python quick_demo.py
```

Choisissez une d√©mo pour tester la d√©tection d'objets avec des mod√®les pr√©-entra√Æn√©s.

### √âtape 4: Ex√©cuter le Lab Complet

```bash
python LAB6_Complete.py
```

Menu interactif :
1. Task 1 seulement
2. Task 2 seulement
3. Task 3 seulement
4. Task 4 seulement
5. **TOUS les tasks** (recommand√© pour le lab complet)

## üìä Fichiers de Sortie

### Apr√®s Task 1 :
```
checkpoint_config1_baseline.pth
checkpoint_config2_high_lr.pth
checkpoint_config3_low_lr.pth
checkpoint_config4_batch2.pth
checkpoint_config5_more_epochs.pth
task1_results.json
```

### Apr√®s Task 2 :
```
model_no_freeze.pth
model_freeze_backbone.pth
model_gradual_unfreeze.pth
model_mobilenet.pth
task2_results.json
```

### Apr√®s Task 3 :
```
model_basic_transform.pth
model_horizontal_flip.pth
model_color_jitter.pth
model_normalized.pth
model_combined_augmentation.pth
task3_results.json
```

### Apr√®s Task 4 :
```
model_task4.pth
task4_output_conf0.5_iou0.5.jpg
task4_no_nms.jpg
task4_with_nms.jpg
```

## üí° Exemples d'Utilisation Avanc√©e

### Utiliser un Mod√®le Entra√Æn√©

```python
import torch
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision import transforms
from PIL import Image

# Charger le mod√®le
model = fasterrcnn_resnet50_fpn(weights="DEFAULT")
num_classes = 2
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

# Charger les poids entra√Æn√©s
model.load_state_dict(torch.load('model_freeze_backbone.pth'))
model.eval()

# Inf√©rence
image = Image.open('test.jpg').convert('RGB')
img_tensor = transforms.ToTensor()(image).unsqueeze(0)

with torch.no_grad():
    predictions = model(img_tensor)[0]

print(f"D√©tections: {len(predictions['boxes'])}")
```

### Entra√Ænement Personnalis√©

```python
from LAB6_Complete import train_with_config

model, results = train_with_config(
    images_dir="data/images",
    labels_dir="data/labels",
    freeze_backbone=True,
    unfreeze_layer4=True,
    backbone_type="resnet50",
    lr=0.0002,
    epochs=5,
    config_name="my_custom_config"
)

print(f"Loss finale: {results['final_loss']}")
print(f"Temps: {results['training_time']}s")
```

## üîç Points Cl√©s pour le Lab

### Task 1 - Ce qu'il faut analyser :
- Quel learning rate converge le mieux ?
- Impact du batch size sur la stabilit√©
- Trade-off entre nombre d'√©poques et overfitting

### Task 2 - Ce qu'il faut comparer :
- Temps d'entra√Ænement avec/sans freezing
- Nombre de param√®tres entra√Ænables
- Performance finale (loss)
- ResNet-50 vs MobileNetV3 (pr√©cision vs vitesse)

### Task 3 - Ce qu'il faut observer :
- Impact de chaque augmentation sur la g√©n√©ralisation
- Robustesse aux variations (flip, color jitter)
- Effet de la normalisation sur la convergence

### Task 4 - Ce qu'il faut √©valuer :
- Trade-off confiance vs nombre de d√©tections
- Importance du NMS pour √©liminer les duplicatas
- Choix du seuil IoU optimal

## üìà M√©triques √† Analyser

### Dans les fichiers JSON :
- `epoch_losses` : √âvolution de la loss par √©poque
- `final_loss` : Loss finale (plus bas = meilleur)
- `training_time` : Temps d'entra√Ænement en secondes
- `trainable_params` : Nombre de param√®tres modifiables

### Dans les visualisations :
- Nombre de d√©tections
- Scores de confiance
- Qualit√© des bounding boxes
- Faux positifs / faux n√©gatifs

## ‚ö†Ô∏è Troubleshooting Courant

### "No images found"
- V√©rifiez que les images sont dans `data/images/`
- V√©rifiez l'extension (.jpg, .jpeg, .png)

### "CUDA out of memory"
- R√©duisez batch_size √† 1
- Utilisez MobileNetV3 au lieu de ResNet-50
- Ou ajoutez au d√©but du script :
  ```python
  device = torch.device('cpu')  # Forcer CPU
  ```

### Loss ne diminue pas
- V√©rifiez le format des labels (YOLO normalis√©)
- Essayez un learning rate plus petit (0.00001)
- V√©rifiez que les bounding boxes sont valides (x1 < x2, y1 < y2)

### Labels vides
Le code g√®re automatiquement les images sans annotations (boxes vides).

## üéì Structure du Rapport Lab

Pour votre rapport, incluez :

1. **Introduction**
   - Contexte de la d√©tection d'objets
   - Mod√®les utilis√©s (Faster R-CNN, etc.)

2. **Task 1 - Hyperparam√®tres**
   - Tableaux comparatifs
   - Graphiques de loss
   - Analyse de la convergence

3. **Task 2 - Transfer Learning**
   - Comparaison des strat√©gies
   - Impact du freezing
   - Choix du backbone

4. **Task 3 - Augmentation**
   - Impact de chaque technique
   - Robustesse am√©lior√©e
   - Recommandations

5. **Task 4 - √âvaluation**
   - Visualisations
   - Analyse NMS
   - Choix des seuils

6. **Conclusion**
   - Meilleure configuration trouv√©e
   - Le√ßons apprises

## üìö Ressources Additionnelles

- **PyTorch Tutorial**: https://pytorch.org/tutorials/
- **Faster R-CNN Paper**: https://arxiv.org/abs/1506.01497
- **COCO Dataset**: https://cocodataset.org/
- **Transfer Learning**: https://cs231n.github.io/transfer-learning/

## ‚úÖ Checklist pour Compl√©ter le Lab

- [ ] Installer les d√©pendances
- [ ] Pr√©parer le dataset (images + labels)
- [ ] Tester quick_demo.py pour v√©rifier l'installation
- [ ] Ex√©cuter Task 1 et analyser les r√©sultats
- [ ] Ex√©cuter Task 2 et comparer les mod√®les
- [ ] Ex√©cuter Task 3 et √©valuer les augmentations
- [ ] Ex√©cuter Task 4 et g√©n√©rer les visualisations
- [ ] Analyser tous les fichiers JSON
- [ ] Sauvegarder les meilleures visualisations
- [ ] R√©diger le rapport avec les conclusions

## üéØ R√©sum√© des Commandes

```bash
# Test rapide sans entra√Ænement
python quick_demo.py

# Lab complet interactif
python LAB6_Complete.py

# Ex√©cuter un exemple sp√©cifique
python Example1.py  # RetinaNet
python Example2.py  # Faster R-CNN avec NMS
python Example3.py  # Training basique
python Example4.py  # Avec freezing
```

## üìû Support

Si vous avez des questions sur le code :
1. Consultez d'abord le README.md d√©taill√©
2. V√©rifiez les erreurs communes dans le troubleshooting
3. Regardez les exemples dans quick_demo.py

---

**Bon courage pour votre LAB6 ! üöÄ**

Le code est complet, test√© et pr√™t √† l'emploi. Tous les tasks du lab sont impl√©ment√©s dans `LAB6_Complete.py`.

