# Guide d'utilisation du cluster ensicompute pour LAB5

## üìã Pr√©requis

1. **Compte Ensimag** : Vous devez avoir un compte informatique Ensimag
2. **Connexion VPN** : Connectez-vous au VPN Ensimag ou grenet.fr (ou utilisez une salle TP)
3. **Environnement pr√©par√©** : Assurez-vous que votre environnement virtuel est configur√©

## üöÄ D√©marrage rapide

### 1. Connexion au cluster

```bash
# Depuis votre machine locale (avec VPN actif)
ssh votre_login@nash.ensimag.fr

# OU depuis une machine de salle TP avec forwarding de cl√©s
ssh -K votre_login@nash.ensimag.fr
```

### 2. Navigation vers votre projet

```bash
cd ~/Bureau/FIB/cours/AVPR/Labs/LAB5
```

### 3. Configuration de l'environnement (premi√®re fois uniquement)

```bash
# Cr√©er et activer l'environnement virtuel
python3 -m venv lab5_env
source lab5_env/bin/activate

# Installer PyTorch avec support CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# Installer les autres d√©pendances
pip install -r requirements.txt
```

### 4. Lancer un job

```bash
# Ex√©cuter toutes les t√¢ches (recommand√©)
./run_cluster.sh

# Ex√©cuter une t√¢che sp√©cifique
./run_cluster.sh --task=1
./run_cluster.sh --task=2
./run_cluster.sh --task=3

# Avec configuration personnalis√©e
./run_cluster.sh --task=all --mem=16GB --cpus=12 --time=8:00:00

# Utiliser une partition sp√©cifique
./run_cluster.sh --task=1 --partition=a40    # GPU A40 (plus puissant)
./run_cluster.sh --task=2 --partition=v100   # GPU Tesla V100
```

## üìä Options disponibles

| Option | Description | Valeur par d√©faut |
|--------|-------------|-------------------|
| `--task=N` | T√¢che √† ex√©cuter (1, 2, 3, ou all) | `all` |
| `--mem=SIZE` | M√©moire RAM allou√©e | `8GB` |
| `--cpus=N` | Nombre de CPUs | `8` |
| `--time=TIME` | Limite de temps (HH:MM:SS) | `4:00:00` |
| `--partition=P` | Partition GPU (rtx6000, v100, a40) | `rtx6000` |

## üîç Surveillance des jobs

### V√©rifier l'√©tat de vos jobs

```bash
# Voir tous vos jobs
squeue -u $USER

# Voir un job sp√©cifique
squeue -j <JOB_ID>

# Voir tous les jobs du cluster
squeue
```

### Suivre les logs en temps r√©el

```bash
# Suivre la sortie standard
tail -f cluster_logs/output/lab5_training_task*_*.out

# Suivre les erreurs
tail -f cluster_logs/errors/lab5_training_task*_*.err
```

### Annuler un job

```bash
# Annuler un job sp√©cifique
scancel <JOB_ID>

# Annuler tous vos jobs
scancel -u $USER
```

## üìÇ Structure des logs

Apr√®s l'ex√©cution, les logs sont organis√©s comme suit :

```
cluster_logs/
‚îú‚îÄ‚îÄ output/          # Sorties standard (.out)
‚îú‚îÄ‚îÄ errors/          # Erreurs (.err)
‚îú‚îÄ‚îÄ checkpoints/     # Checkpoints de mod√®les (si applicable)
‚îî‚îÄ‚îÄ slurm_job_*.sh   # Scripts SLURM g√©n√©r√©s
```

## üñ•Ô∏è Informations sur les GPU disponibles

### RTX 6000 (Quadro) - Partition par d√©faut
- **N≈ìuds** : turing-1 √† turing-11 (33 GPUs au total)
- **VRAM** : 24GB par GPU
- **Bon pour** : Entra√Ænement standard, charge mod√©r√©e

### Tesla V100
- **N≈ìuds** : tesla (1 GPU)
- **VRAM** : 32GB
- **Bon pour** : Mod√®les n√©cessitant plus de m√©moire

### NVIDIA A40
- **N≈ìuds** : ampere (3 GPUs)
- **VRAM** : 46GB par GPU
- **Bon pour** : Mod√®les tr√®s larges, batch size √©lev√©

## üí° Conseils d'utilisation

### 1. Ressources appropri√©es

Pour LAB5 (MNIST), les valeurs par d√©faut sont suffisantes :
```bash
./run_cluster.sh --mem=8GB --cpus=8 --time=4:00:00
```

Si vous avez des timeouts ou des erreurs de m√©moire :
```bash
./run_cluster.sh --mem=16GB --cpus=12 --time=8:00:00
```

### 2. Tester d'abord localement

Avant de lancer sur le cluster, testez rapidement en local :
```bash
python3 lab5_runner.py --task 1  # Test rapide d'une t√¢che
```

### 3. Ex√©cution d√©tach√©e

Le script utilise `sbatch`, donc votre job continue m√™me si vous vous d√©connectez. Vous pouvez :
- Fermer votre terminal
- Vous d√©connecter du VPN
- Revenir plus tard pour v√©rifier les r√©sultats

### 4. Optimisation des ressources

```bash
# Pour des exp√©rimentations rapides
./run_cluster.sh --task=1 --time=1:00:00 --mem=4GB --cpus=4

# Pour des entra√Ænements longs avec beaucoup de variations
./run_cluster.sh --task=all --time=12:00:00 --mem=16GB --cpus=12
```

## üêõ R√©solution de probl√®mes

### Job en attente (PD - Pending)
```bash
# V√©rifier pourquoi
squeue -j <JOB_ID> -o "%.18i %.9P %.8j %.8u %.2t %.10M %.6D %R"

# Raisons courantes :
# - Resources : Pas assez de ressources disponibles, attendez
# - Priority : D'autres jobs ont la priorit√©
```

### Job √©choue imm√©diatement
```bash
# V√©rifier les logs d'erreur
cat cluster_logs/errors/lab5_training_task*_*.err

# Probl√®mes courants :
# - Environnement virtuel non activ√©
# - CUDA non disponible
# - Fichiers de donn√©es manquants
```

### Erreurs CUDA
```bash
# V√©rifier que PyTorch d√©tecte CUDA
python3 -c "import torch; print(torch.cuda.is_available())"

# Si False, r√©installer PyTorch avec CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### M√©moire insuffisante
```bash
# Augmenter la m√©moire allou√©e
./run_cluster.sh --mem=16GB

# Ou r√©duire le batch size dans votre code
```

## üìß Support

En cas de probl√®me avec le cluster :
- Email : support.info@ensimag.fr
- Documentation : https://ensicompute.ensimag.fr (si disponible)

## üìù Exemple de workflow complet

```bash
# 1. Connexion
ssh votre_login@nash.ensimag.fr

# 2. Navigation
cd ~/Bureau/FIB/cours/AVPR/Labs/LAB5

# 3. V√©rification de l'environnement (premi√®re fois)
source lab5_env/bin/activate
python3 -c "import torch; print(torch.cuda.is_available())"

# 4. Lancement du job
./run_cluster.sh --task=all

# 5. Note du Job ID affich√©
# Job ID: 12345

# 6. Surveillance
squeue -j 12345
tail -f cluster_logs/output/lab5_training_task*_*.out

# 7. D√©connexion (le job continue)
exit

# 8. Reconnexion plus tard
ssh votre_login@nash.ensimag.fr
cd ~/Bureau/FIB/cours/AVPR/Labs/LAB5

# 9. V√©rification des r√©sultats
ls -lh *.png *.pth  # Mod√®les et graphiques g√©n√©r√©s
cat cluster_logs/output/lab5_training_task*_*.out | grep -i "accuracy\|loss"
```

## ‚úÖ Checklist avant soumission

- [ ] Environnement virtuel cr√©√© et d√©pendances install√©es
- [ ] Code test√© localement (au moins un petit test)
- [ ] Script run_cluster.sh ex√©cutable (`chmod +x run_cluster.sh`)
- [ ] Connect√© √† nash.ensimag.fr
- [ ] R√©pertoire de travail correct
- [ ] Logs et checkpoints pr√©c√©dents sauvegard√©s si n√©cessaire

Bon entra√Ænement ! üöÄ

