# üéØ Bag of Words (BoW) pour la Reconnaissance d'Images - LAB4

## üìã Vue d'Ensemble

Ce projet impl√©mente un syst√®me de reconnaissance d'images bas√© sur le mod√®le **Bag of Words (BoW)** avec des descripteurs SIFT et un classificateur SVM. Le code a √©t√© optimis√© pour corriger les probl√®mes de performance et d'overfitting.

## ‚úÖ Am√©liorations Apport√©es

### 1. **Performance (10-50x plus rapide)**
- ‚úÖ Vectorisation de `extractFeatures()` 
- ‚úÖ Op√©rations batch au lieu de boucles imbriqu√©es
- ‚úÖ Utilisation de `np.bincount()` pour les histogrammes

### 2. **Sauvegarde Automatique**
- ‚úÖ Toutes les figures sont sauvegard√©es (pas affich√©es)
- ‚úÖ Organisation en dossiers par t√¢che
- ‚úÖ Noms de fichiers descriptifs

### 3. **D√©tection d'Overfitting**
- ‚úÖ Comparaison Train CV vs Test
- ‚úÖ Rapport d√©taill√© par classe
- ‚úÖ Matrices de confusion pour chaque configuration

### 4. **Gestion d'Erreurs**
- ‚úÖ V√©rification des images None
- ‚úÖ Filtrage des extensions de fichiers
- ‚úÖ Seed fixe pour la reproductibilit√©

## üöÄ Utilisation

### Installation
```bash
# Installer les d√©pendances
pip install -r requirements.txt
```

### Ex√©cution

#### Option 1: Code Principal (Recommand√©)
```bash
# Ex√©cuter les deux t√¢ches
python BOW_for_image_recognition.py --task both

# Ou juste Task 1 (exploration des param√®tres)
python BOW_for_image_recognition.py --task task1

# Ou juste Task 2 (impact de l'augmentation)
python BOW_for_image_recognition.py --task task2
```

#### Option 2: Version Avanc√©e
```bash
# Tester plusieurs configurations avec RBF kernel
python BOW_improved.py
```

## üìä R√©sultats Attendus

### Task 1: Exploration des Param√®tres

| Configuration | Pr√©cision | Commentaire |
|--------------|-----------|-------------|
| **Baseline (50 clusters)** | **62.4%** | ‚úÖ **OPTIMAL** |
| More Clusters (150) | 61.0% | L√©g√®re baisse |
| Fewer Clusters (25) | 47.6% | ‚ùå Insuffisant |
| More Octave Layers (5) | 60.5% | L√©g√®re baisse |
| Lower Contrast (0.02) | 58.6% | Baisse mod√©r√©e |

**Conclusion:** 50 clusters avec param√®tres par d√©faut est optimal pour ce dataset.

### Task 2: Impact de l'Augmentation

| Configuration | Pr√©cision | Am√©lioration |
|--------------|-----------|--------------|
| Sans augmentation | 61.0% | - |
| Avec augmentation | 61.4% | +0.4% seulement |

**Conclusion:** L'augmentation n'apporte presque rien sur ce dataset (+0.4% seulement).

### BOW_improved.py: D√©tection d'Overfitting

| Configuration | Train CV | Test | √âcart |
|--------------|----------|------|-------|
| Baseline (50 clusters) | 61.7% | 61.0% | -0.7% ‚úÖ |
| More clusters (150) | 68.4% | 60.0% | -8.4% ‚ö†Ô∏è |
| With augmentation (50) | **86.9%** | 55.7% | **-31.2%** ‚ùå |

**Conclusion:** L'augmentation avec RBF kernel cause un **overfitting s√©v√®re**.

## üìÇ Structure des R√©sultats

Apr√®s ex√©cution, les r√©sultats sont organis√©s ainsi:

```
results/
‚îú‚îÄ‚îÄ ANALYSIS_REPORT.md                    # Rapport d√©taill√©
‚îÇ
‚îú‚îÄ‚îÄ task1_parameter_exploration/
‚îÇ   ‚îú‚îÄ‚îÄ parameter_comparison.png          # Comparaison graphique
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix_50clusters.png   # Matrices pour chaque config
‚îÇ
‚îú‚îÄ‚îÄ task2_augmentation/
‚îÇ   ‚îú‚îÄ‚îÄ augmentation_comparison.png       # Avec vs sans
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix_with_augmentation.png
‚îÇ
‚îî‚îÄ‚îÄ improved_models/
    ‚îú‚îÄ‚îÄ model_comparison.png              # Toutes les configs
    ‚îî‚îÄ‚îÄ confusion_matrix_*.png            # Une par configuration
```

## üéØ Configuration Optimale

```python
# MEILLEURS PARAM√àTRES
n_clusters = 50
kernel = 'linear'
nOctaveLayers = 3
contrastThreshold = 0.04
augment = False  # PAS d'augmentation!
C = 0.1
class_weight = 'balanced'
```

**Pr√©cision: 62.4%**

## üìà Probl√®mes par Classe

| Classe | F1-Score | Diagnostic |
|--------|----------|------------|
| face | 0.79 | ‚úÖ Tr√®s bien |
| sea | 0.78 | ‚úÖ Tr√®s bien |
| house_building | 0.64 | ‚úÖ OK |
| city | 0.62 | ‚úÖ OK |
| office | 0.58 | ‚ö†Ô∏è Beaucoup de faux positifs |
| green | 0.52 | ‚ö†Ô∏è Features peu distinctives |
| **house_indoor** | **0.27** | ‚ùå **TR√àS MAUVAIS** (42 images seulement) |

## üîç Analyse des Probl√®mes

### Pourquoi l'augmentation ne fonctionne pas ?

1. **Dataset trop petit** (807 images train)
   - L'augmentation cr√©e 4000-7000 images artificielles
   - Le mod√®le "m√©morise" au lieu de g√©n√©raliser

2. **SVM RBF trop flexible**
   - Avec C=100 et gamma='scale', le mod√®le surfit
   - Train accuracy: 86-91% vs Test: 55-60%

3. **Augmentations non-r√©alistes**
   - Rotations de 90¬∞ changent l'orientation
   - Le mod√®le apprend des patterns artificiels

### Classes Probl√©matiques

1. **house_indoor (F1: 0.27)**
   - Seulement 42 images d'entra√Ænement
   - Confondu avec "office" (features similaires)
   - **Solution:** Collecter plus de donn√©es

2. **green (F1: 0.52)**
   - Features SIFT peu distinctives (textures naturelles)
   - **Solution:** Ajouter features de couleur

3. **office (precision: 0.48)**
   - Pr√©dit trop souvent (recall: 0.73)
   - **Solution:** Ajuster les poids de classe

## üí° Recommandations

### ‚úÖ √Ä Faire

1. **Utiliser la configuration baseline** (50 clusters, linear)
   - Meilleure pr√©cision: 62.4%
   - Pas d'overfitting
   - Rapide √† entra√Æner

2. **Collecter plus de donn√©es** pour house_indoor
   - Minimum 100 images par classe
   - Donn√©es r√©elles > Augmentation artificielle

3. **Essayer Spatial Pyramid Matching**
   - Diviser l'image en grilles
   - Capturer l'information spatiale

### ‚ùå √Ä √âviter

1. **Ne PAS utiliser l'augmentation** sur ce dataset
   - Cause de l'overfitting s√©v√®re
   - N'am√©liore pas la g√©n√©ralisation

2. **Ne PAS augmenter trop les clusters**
   - 150 clusters ‚Üí overfitting l√©ger
   - 50 est optimal pour ce dataset

3. **Ne PAS utiliser RBF kernel avec augmentation**
   - Trop de flexibilit√© = overfitting
   - Linear kernel plus robuste

## üîß D√©tails Techniques

### Vectorisation de extractFeatures()

**Avant (lent):**
```python
for i in range(image_count):
    for j in range(len(descriptor_list[i])):
        feature = descriptor_list[i][j].reshape(1, 128)
        idx = kmeans.predict(feature)  # Un √† la fois!
        im_features[i][idx] += 1
```

**Apr√®s (rapide):**
```python
for i in range(image_count):
    if len(descriptor_list[i]) > 0:
        idx = kmeans.predict(descriptor_list[i])  # Tous en batch!
        hist = np.bincount(idx, minlength=no_clusters)
        im_features[i] = hist[:no_clusters]
```

**Gain: 10-50x plus rapide**

### Meilleure Recherche d'Hyperparam√®tres

**Avant:**
```python
Cs = [0.5, 0.1, 0.15, 0.2, 0.3]
gammas = [0.1, 0.11, 0.095, 0.105]
# ‚Üí 20 combinaisons, plage √©troite
```

**Apr√®s:**
```python
Cs = [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]
gammas = ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]  # Si RBF
# ‚Üí 36 combinaisons, plage large
```

## üìö Fichiers du Projet

- `BOW_for_image_recognition.py` - Code principal optimis√©
- `BOW_improved.py` - Version avanc√©e avec d√©tection d'overfitting
- `results/ANALYSIS_REPORT.md` - Rapport d√©taill√© d'analyse
- `requirements.txt` - D√©pendances Python

## üéì Le√ßons Apprises

1. **Plus de donn√©es ‚â† Toujours mieux**
   - L'augmentation artificielle peut nuire
   - Surveiller l'overfitting (Train vs Test)

2. **Simplicit√© parfois meilleure**
   - 50 clusters > 150 clusters
   - Linear kernel robuste
   - Pas d'augmentation n√©cessaire

3. **Importance des donn√©es √©quilibr√©es**
   - house_indoor: 42 images vs sea: 142 images
   - Explique les mauvaises performances

4. **Vectorisation cruciale**
   - 10-50x de gain de performance
   - Toujours privil√©gier les op√©rations batch

## üìû Support

Pour plus de d√©tails, voir:
- `results/ANALYSIS_REPORT.md` - Analyse compl√®te des r√©sultats
- `IMPROVEMENTS.md` - Documentation technique des am√©liorations

---

**Auteur:** Optimis√© pour LAB4 AVPR
**Date:** 2025-11-26
**Meilleure Configuration:** Baseline (50 clusters, linear, no augmentation)
**Meilleure Pr√©cision:** 62.4%

